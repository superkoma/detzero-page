<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DetZero</title>
  <link rel="icon" type="image/x-icon" href="static/images/header.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">DetZero: Rethinking Offboard 3D Object Detection with Long-term Sequential Point Clouds</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://superkoma.github.io" target="_blank">Tao Ma</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="https://github.com/jokester-zzz" target="_blank">Xuemeng Yang</a><sup>2</sup>,</span>
              <span class="author-block">
                Hongbin Zhou<sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://sankin97.github.io/" target="_blank">Xin Li</a><sup>3,2</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=K0PpvLkAAAAJ&hl=en" target="_blank">Botian Shi</a><sup>2</sup>,</span>
              <br>
              <span class="author-block">
                Junjie Liu<sup>4</sup>,</span>
              <span class="author-block">
                Yuchen Yang<sup>5,2</sup>,</span>
              <span class="author-block">
                Zhizheng Liu<sup>6</sup>,</span>
              <br>
              <span class="author-block">
                Liang He<sup>3</sup>,</span>
              <span class="author-block">
                Yu Qiao<sup>2</sup>,</span>
              <span class="author-block">
                <a href="http://liyikang.top" target="_blank">Yikang Li</a><sup>2 *</sup>,</span>
              <span class="author-block">
                <a href="https://www.ee.cuhk.edu.hk/~hsli/" target="_blank">Hongsheng Li</a><sup>1,2,7 *</sup>
              </span>
              </div>

                <!-- <br> -->
                <div class="is-size-5 publication-authors" style="margin-top:10px;">
                  <span class="author-block" style="font-size:17px">
                    <sup>1</sup><a href="https://mmlab.ie.cuhk.edu.hk" target="_blank"> MMLab, CUHK</a>
                    &nbsp;&nbsp;<sup>2</sup> Shanghai AI Lab &nbsp;&nbsp;<sup>3</sup> East China Normal University
                  </span>
                  <br>
                  <span class="author-block" style="font-size:17px">
                    <sup>4</sup> South China University of Technology
                    &nbsp;&nbsp;<sup>5</sup> Fudan University &nbsp;&nbsp;<sup>6</sup> ETH Zurich &nbsp;&nbsp;<sup>7</sup> CPII
                  </span>
                  <!-- <br> -->
                  <!-- <span class="author-block">Conferance name and year</span> -->
                  <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Authors</small></span>
                  <br>
                  <span class="author-block"><b>ICCV 2023</b></span>
                </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2306.06023.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://waymo.com/open/challenges/2020/3d-detection/" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <!-- <i class="fas fa-file-pdf"></i> -->
                        <img src="static/images/waymo-icon.png"/>
                      </span>
                      <span>Leaderboard</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/PJLab-ADG/DetZero" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2306.06023" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container">
    <div class="hero-body" style="width:85%; margin:0 auto;">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <source src="static/videos/detzero-res.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Existing offboard 3D detectors always follow a modular pipeline design to take advantage of unlimited sequential point clouds. We have found that the full potential of offboard 3D detectors is not explored mainly due to two reasons: (1) the onboard multi-object tracker cannot generate sufficient complete object trajectories, and (2) the motion state of objects poses an inevitable challenge for the object-centric refining stage in leveraging the long-term temporal context representation.
          </p>
          <p>
            To tackle these problems, we propose a novel paradigm of offboard 3D object detection, named DetZero. Concretely, an offline tracker coupled with a multi-frame detector is proposed to focus on the completeness of generated object tracks. An attention-mechanism refining module is proposed to strengthen contextual information interaction across long-term sequential point clouds for object refining with decomposed regression methods.
          </p>
          <p>
            Extensive experiments on Waymo Open Dataset show our DetZero outperforms all state-of-the-art onboard and offboard 3D detection methods. Notably, DetZero ranks 1st place on Waymo 3D object detection leaderboard with 85.15 mAPH (L2) detection performance. Further experiments validate the application of taking the place of human labels with such high-quality results. Our empirical study leads to rethinking conventions and interesting findings that can guide future research on offboard 3D object detection.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div style="width:80%; margin:0 auto;">
        <img src="static/images/detzero-framework.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The overall framework of DetZero. 
        </h2>
        <p class="has-text-justified">
          The multi-frame detector takes as input N frames of point clouds, the following offline tracker generates accurate and complete object tracks. For each object track, we prepare its object-specific LiDAR points sequence and tracked box sequence. Consequently, we refine the object tracks through 3 simultaneous steps: refine the geometry size, smooth the motion trajectory and update the confidence score. Afterwards, they are combined together and transformed through world-to-frame poses as the final "auto labels".
        </p>
      </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Attribute-based Refining Process</h2>
      <div style="width:100%; height:350px; padding:25px; padding-top:0px;">
        <div style="width:45%; height:350px; float:left;">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/vehicle-refine.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            A Vehicle sample of GRM & PRM processing.
          </h2>
        </div>
        <div style="width:45%; height:350px; float:right;">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/pedestrian-refine.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            A Pedestrian sample of GRM & PRM processing.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Comparison after Refining</h2>
      <div style="width:90%; height:100%; margin:0 auto; padding:25px; padding-top:0px;">
        <img src="static/images/grm-res.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The predicted boxes of detection module is colored in red, blue boxes are predicted by GRM.
        </h2>
      </div>

      <div style="width:90%; height:340px; margin:0 auto; margin-top:10px; padding:25px; padding-top:0px; padding-bottom:0px;">
        <img src="static/images/prm-res.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          The trajectories of static objects are more aligned and stable, those of dynamic objects are more smooth.
        </h2>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Comparison on BEV</h2>
      <div style="width:65%; margin:0 auto; height:450px; padding:25px; padding-top:0px;">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/bev-compare.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            The most of Red and Blue boxes are close to the IoU threshold of 0.7.
          </h2>
      </div>
    </div>
  </div>
</section>


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{ma2023detzero,
          title = {DetZero: Rethinking Offboard 3D Object Detection with Long-term Sequential Point Clouds},
          author = {Tao Ma and Xuemeng Yang and Hongbin Zhou and Xin Li and Botian Shi and Junjie Liu and Yuchen Yang and Zhizheng Liu and Liang He and Yu Qiao and Yikang Li and Hongsheng Li},
          booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
          year = {2023}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
